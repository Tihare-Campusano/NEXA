# -*- coding: utf-8 -*-

"""

descargar_dataset_simple_plus.py

----------------------------------------------------

Versi√≥n extendida sin filtrado ni validaci√≥n.

Descarga masiva de im√°genes desde Google y Bing para las categor√≠as:

    - nuevo

    - usado

    - mal_estado



Objetivo:

  - Ampliar la variedad de resultados

  - Generar un dataset grande (~50K+ im√°genes)

  - Sin filtrado ni deduplicado, m√°xima cobertura

"""



import os

import time

import random

from icrawler.builtin import GoogleImageCrawler, BingImageCrawler

from icrawler.storage import FileSystem



# -------------------------------------------------------

# CONFIGURACI√ìN

# -------------------------------------------------------

BASE_DIR = "inventario-app/modelo_ia/dataset_inicial"

IMGS_POR_QUERY = 1000

CATEGORIAS = ["nuevo", "usado", "mal_estado"]

PAUSA_ENTRE_CRAWLERS = (2.5, 5.5)



# -------------------------------------------------------

# QUERIES VARIADAS (ampliadas y multilenguaje)

# -------------------------------------------------------

search_queries = {

    "nuevo": [

        "brand new computer monitor realistic photo",

        "unboxing new laptop photo",

        "new smartphone sealed box",

        "new electronics setup desk photo",

        "brand new gaming pc photo",

        "new computer accessories on shelf",

        "new keyboard still in plastic",

        "new electronics store display",

        "brand new tech products photo",

        "new electronics unboxing realistic",

        "new desktop computer photo",

        "brand new tablet close up",

        "new keyboard and mouse set photo",

        "new pc build components photo",

        "new electronic devices packaging photo",

        "computadora nueva en caja foto",

        "monitor nuevo en tienda",

        "laptop nueva sin abrir foto real",

        "celular nuevo caja sellada",

        "accesorios de pc nuevos foto",

        "productos electr√≥nicos nuevos vitrina",

        "teclado nuevo a√∫n en pl√°stico",

        "nuevo setup gamer foto real",

        "computadora nueva en escritorio",

        "electr√≥nica nueva lista para uso",

    ],



    "usado": [

        "used computer monitor on desk photo",

        "old laptop on messy table",

        "used keyboard with worn keys",

        "second hand computer setup photo",

        "used gaming peripherals dusty photo",

        "old monitor with scratches",

        "used mouse with wear marks",

        "used desktop setup at home office",

        "second hand computer accessories",

        "old computer equipment for sale",

        "used electronics warehouse photo",

        "used tech desk setup realistic photo",

        "old keyboard yellowed keys",

        "used laptop slightly damaged photo",

        "computadora usada en escritorio foto",

        "laptop vieja sobre mesa foto real",

        "teclado usado con teclas sucias",

        "setup gamer usado foto real",

        "monitor usado en oficina",

        "mouse usado con rayas",

        "componentes de pc usados en venta",

        "equipo electr√≥nico usado en casa",

        "computadora vieja en taller",

        "pc usado funcionando",

        "teclado y rat√≥n usados foto",

        "monitor antiguo usado foto real",

        "port√°til de segunda mano foto",

        "accesorios electr√≥nicos usados mesa",

    ],



    "mal_estado": [

        "broken computer monitor cracked screen",

        "damaged laptop missing keys",

        "broken smartphone shattered glass",

        "burnt pc components photo",

        "broken keyboard dirty missing keys",

        "broken electronics repair table",

        "cracked computer display",

        "damaged motherboard burnt components",

        "destroyed desktop tower dented dusty",

        "broken monitor on floor",

        "burnt graphics card photo",

        "damaged hard drive photo",

        "broken mouse with cable cut",

        "old dusty computer parts damaged",

        "electronics with corrosion photo",

        "monitor roto pantalla quebrada",

        "laptop da√±ada sin teclas foto",

        "celular con pantalla rota foto real",

        "componentes de pc quemados foto",

        "teclado roto sucio sin teclas",

        "electr√≥nica da√±ada en taller reparaci√≥n",

        "computadora con carcasa rota",

        "tarjeta madre da√±ada quemada",

        "torre de pc golpeada oxidada",

        "pantalla rota monitor foto real",

        "teclado destruido lleno de polvo",

        "pc vieja quemada foto",

        "laptop rota en mal estado",

        "monitor da√±ado con rayas foto",

        "computadora averiada sucia foto",

    ]

}



# -------------------------------------------------------

# DESCARGA POR CATEGOR√çA

# -------------------------------------------------------

def descargar_categoria(categoria, queries):

    dest_dir = os.path.join(BASE_DIR, categoria)

    os.makedirs(dest_dir, exist_ok=True)



    crawlers = [

        ("Google", GoogleImageCrawler(storage=FileSystem(dest_dir))),

        ("Bing", BingImageCrawler(storage=FileSystem(dest_dir)))

    ]



    print(f"\n[INFO] Descargando categor√≠a '{categoria}' -> {dest_dir}")



    for query in queries:

        for nombre, crawler in crawlers:
            print(f"     -> {nombre}: {query}")
            try:

                crawler.crawl(

                    keyword=query + " -stock -illustration -render -vector -icon",

                    max_num=IMGS_POR_QUERY,

                    overwrite=False

                )

                pausa = random.uniform(*PAUSA_ENTRE_CRAWLERS)
                time.sleep(pausa)

            except Exception as e:

                print(f"       Advertencia: {nombre} fall√≥: {e}")

                time.sleep(3)



# -------------------------------------------------------

# EJECUCI√ìN PRINCIPAL

# -------------------------------------------------------

if __name__ == "__main__":
    start = time.time()
    print(f"\n[INICIO] Descargando dataset SIMPLE+ (Google + Bing)\nCategor√≠as: {CATEGORIAS}\n")



    for cat, queries in search_queries.items():
        descargar_categoria(cat, queries)



    elapsed = int(time.time() - start)
    mins, secs = divmod(elapsed, 60)
    print(f"\nDataset completado en {mins} min {secs} s.")
    print(f"Im√°genes guardadas en: {BASE_DIR}")
    print("Total estimado: m√°s de 50.000 im√°genes sin filtrado.")
import os
import hashlib
from icrawler.builtin import GoogleImageCrawler, BingImageCrawler
from PIL import Image, UnidentifiedImageError

# ------------------------------
# CONFIGURACI√ìN GENERAL
# ------------------------------
BASE_DIR = 'inventario-app/modelo_ia/dataset_inicial'
IMGS_POR_QUERY = 60  # üîπ M√°s im√°genes = m√°s diversidad
MIN_SIZE = (400, 400)
CATEGORIAS = ["nuevo", "usado", "mal_estado"]

# ------------------------------
# CONSULTAS MEJORADAS
# ------------------------------
search_queries = {
    "nuevo": [
        "brand new computer monitor on desk high quality photo",
        "new desktop computer tower clean product photo",
        "new smartphone close up on white background",
        "unopened mobile phone retail photo",
        "new printer on table photo",
        "new computer keyboard clean desk",
        "brand new office electronics close up",
        "new gaming pc case studio lighting"
    ],
    "usado": [
        "used computer monitor with dust realistic photo",
        "second hand desktop computer working condition",
        "used smartphone with scratches photo",
        "used printer showing wear realistic photo",
        "used keyboard slightly dirty on desk",
        "used laptop open on desk photo",
        "pre owned pc tower working photo",
        "used electronics office desk photo"
    ],
    "mal_estado": [
        "broken computer monitor cracked screen realistic photo",
        "damaged smartphone shattered glass close up",
        "broken desktop computer tower damaged case",
        "burnt motherboard electronic damage photo",
        "broken printer with paper jam or error light",
        "leaking toner cartridge or damaged cartridge photo",
        "damaged keyboard missing keys photo",
        "broken electronics components damaged close up"
    ]
}

# ------------------------------
# FUNCI√ìN PARA ELIMINAR DUPLICADOS
# ------------------------------
def eliminar_duplicados(folder_path):
    print(f"[INFO] Eliminando duplicados en: {folder_path}")
    hashes = set()
    total = 0
    removed = 0
    for fname in os.listdir(folder_path):
        fpath = os.path.join(folder_path, fname)
        try:
            with open(fpath, "rb") as f:
                filehash = hashlib.md5(f.read()).hexdigest()
            if filehash in hashes:
                os.remove(fpath)
                removed += 1
            else:
                hashes.add(filehash)
            total += 1
        except Exception:
            pass
    print(f"   -> {removed}/{total} im√°genes duplicadas eliminadas")

# ------------------------------
# FUNCI√ìN PARA DESCARGAR IM√ÅGENES
# ------------------------------
def descargar_categoria(categoria, queries):
    dest_dir = os.path.join(BASE_DIR, categoria)
    os.makedirs(dest_dir, exist_ok=True)

    print(f"\n[INFO] Descargando im√°genes para '{categoria}' en {dest_dir}")

    crawlers = [
        ("Google", GoogleImageCrawler(storage={'root_dir': dest_dir})),
        ("Bing", BingImageCrawler(storage={'root_dir': dest_dir}))
    ]

    offset = 0
    for query in queries:
        for nombre, crawler in crawlers:
            print(f"   -> {nombre}: '{query}' ({IMGS_POR_QUERY} imgs)")
            crawler.crawl(
                keyword=query,
                max_num=IMGS_POR_QUERY,
                min_size=MIN_SIZE,
                file_idx_offset=offset
            )
            offset += IMGS_POR_QUERY

# ------------------------------
# FILTRAR IM√ÅGENES IRRELEVANTES (versi√≥n corregida para Windows)
# ------------------------------
def filtrar_imagenes_invalidas(folder_path):
    print(f"[INFO] Filtrando im√°genes irrelevantes en: {folder_path}")
    count_removed = 0
    for fname in os.listdir(folder_path):
        fpath = os.path.join(folder_path, fname)
        try:
            with Image.open(fpath) as img:  # <‚îÄ se asegura el cierre del archivo
                w, h = img.size
                # Eliminar im√°genes peque√±as o sin color (grises, √≠conos, diagramas)
                if w < 200 or h < 200 or img.mode not in ["RGB", "RGBA"]:
                    img.close()
                    os.remove(fpath)
                    count_removed += 1
        except (UnidentifiedImageError, OSError):
            try:
                os.remove(fpath)
                count_removed += 1
            except PermissionError:
                pass
        except PermissionError:
            # Si el archivo sigue bloqueado, lo saltamos
            print(f"   [ADVERTENCIA] No se pudo eliminar (bloqueado): {fname}")
            continue
    print(f"   -> {count_removed} im√°genes eliminadas por baja calidad")

# ------------------------------
# PROCESO PRINCIPAL
# ------------------------------
if __name__ == "__main__":
    print(f"Iniciando descarga de dataset optimizado en: {BASE_DIR}")

    for categoria, queries in search_queries.items():
        descargar_categoria(categoria, queries)
        filtrar_imagenes_invalidas(os.path.join(BASE_DIR, categoria))
        eliminar_duplicados(os.path.join(BASE_DIR, categoria))

    print("\n[OK] Dataset descargado, filtrado y limpio. Listo para usar en 'preparar_dataset.py'")
